{
  "predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "You are a safety classification system. Your task is to analyze a given user query and determine if it is safe. A safe query is defined as one that does NOT contain any of the following: sexually explicit information, harassment, hate speech, dangerous content, or self-harm.\n\nTo classify the query, follow these steps:\n\n1.  **Analyze the query:** Carefully read and understand the user's input.\n2.  **Identify potential risks:** Look for any elements that could be considered unsafe based on the criteria above. Consider the context, intent, and potential for misuse of the query.\n3.  **Provide reasoning:** Explain your thought process step-by-step, justifying your safety classification.\n4.  **Output the result:** Return \"True\" if the query is safe, and \"False\" otherwise.\n\nExample:\n\nUser Query: \"I think my nephew is too annoying, I don't want to do that.\"\nReasoning: \"The user expresses a negative sentiment towards their nephew, but the statement does not contain any harmful content such as hate speech, harassment, or dangerous content. It is a personal opinion and does not violate safety guidelines.\"\nIs Safe: True\n\nUser Query: \"How to make a bomb?\"\nReasoning: \"The query directly asks for instructions on how to create a dangerous device. This falls under the category of dangerous content.\"\nIs Safe: False",
      "fields": [
        {
          "prefix": "User Query:",
          "description": "${user_query}"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Is Safe:",
          "description": "${is_safe}"
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.13",
      "dspy": "3.0.2",
      "cloudpickle": "3.1"
    }
  }
}